{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformer Model - Translator English to Vietnamese - Training","metadata":{}},{"cell_type":"markdown","source":"## Import Library","metadata":{}},{"cell_type":"code","source":"!pip install underthesea","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:35:36.603400Z","iopub.execute_input":"2024-06-16T09:35:36.603734Z","iopub.status.idle":"2024-06-16T09:35:51.509208Z","shell.execute_reply.started":"2024-06-16T09:35:36.603705Z","shell.execute_reply":"2024-06-16T09:35:51.508149Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.10/site-packages (from underthesea) (8.1.7)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from underthesea) (3.2.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from underthesea) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.4.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from underthesea) (6.0.1)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->underthesea) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (2024.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.11.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (3.2.0)\nDownloading underthesea-6.8.3-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.10 underthesea-6.8.3 underthesea-core-1.0.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# Necessary\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re,string # For Regular Expressions, string handle\nfrom typing import Iterable, List # For building vocab, yield helper\nimport math\nimport time\nimport random\nimport os\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Dataset hugging face\nfrom datasets import load_dataset\n\n# Natural language Processing & Initializing Vocabulary\nfrom underthesea import word_tokenize\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\n\n# Building Transformer and Training\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence # take the max size and add padding_token to the smaller\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:35:51.510981Z","iopub.execute_input":"2024-06-16T09:35:51.511336Z","iopub.status.idle":"2024-06-16T09:35:58.049521Z","shell.execute_reply.started":"2024-06-16T09:35:51.511307Z","shell.execute_reply":"2024-06-16T09:35:58.048562Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset from Hugging Face","metadata":{}},{"cell_type":"markdown","source":"IWSLT. (n.d.). mt_eng_vietnamese.py. Hugging Face. Retrieved June 14, 2024, from https://huggingface.co/datasets/IWSLT/mt_eng_vietnamese/blob/main/mt_eng_vietnamese.py","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"ncduy/mt-en-vi\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:35:58.050649Z","iopub.execute_input":"2024-06-16T09:35:58.051045Z","iopub.status.idle":"2024-06-16T09:36:21.383545Z","shell.execute_reply.started":"2024-06-16T09:35:58.051022Z","shell.execute_reply":"2024-06-16T09:36:21.382668Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3dbb826b96d4b839766b8e2e60912d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/597M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee3379bd10a47acad6da6baeb6c7a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.45M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb9a38c6ac448568cce991723829e43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91937f7cb3224a85b9a3c339c81222a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2884451 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a47d9abf66d487baecf675175a77414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11316 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae7ac55006c14d4b82cbf15908dd82a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11225 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c99238fcd63404d8361bc664277e9c9"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['en', 'vi', 'source'],\n        num_rows: 2884451\n    })\n    validation: Dataset({\n        features: ['en', 'vi', 'source'],\n        num_rows: 11316\n    })\n    test: Dataset({\n        features: ['en', 'vi', 'source'],\n        num_rows: 11225\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"- Just take 500.000 rows from train, all for others","metadata":{}},{"cell_type":"code","source":"df_train = pd.DataFrame(dataset['train'][:200000]).drop(columns=['source'])\ndf_valid = pd.DataFrame(dataset['validation']).drop(columns=['source'])\ndf_test = pd.DataFrame(dataset['test']).drop(columns=['source'])","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:21.386193Z","iopub.execute_input":"2024-06-16T09:36:21.386813Z","iopub.status.idle":"2024-06-16T09:36:23.506317Z","shell.execute_reply.started":"2024-06-16T09:36:21.386784Z","shell.execute_reply":"2024-06-16T09:36:23.505204Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head(3), df_valid.head(3), df_test.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:23.507500Z","iopub.execute_input":"2024-06-16T09:36:23.507867Z","iopub.status.idle":"2024-06-16T09:36:23.520427Z","shell.execute_reply.started":"2024-06-16T09:36:23.507832Z","shell.execute_reply":"2024-06-16T09:36:23.519481Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(                                           en  \\\n 0       - Sorry, that question's not on here.   \n 1  He wants you to come with him immediately.   \n 2        I thought we could use some company.   \n \n                                                   vi  \n 0    - Xin lỗi, nhưng mà ở đây không có câu hỏi đấy.  \n 1          Ông ấy muốn bố đi với ông ấy ngay lập tức  \n 2  Tôi nghĩ chúng ta có thể muốn vài người bạn đồ...  ,\n                                                   en  \\\n 0  In August 1764, Bertin permitted the export of...   \n 1  Homeless women used to be invisible to me but ...   \n 2  Pumping water site for artificial infiltration...   \n \n                                                   vi  \n 0  Tháng 8 năm 1764, Bertin lại cho phép xuất khẩ...  \n 1  Tôi từng không hề để ý đến những người phụ nữ ...  \n 2        Bơm nước cho thấm nhân tạo ở quận Sojovice.  ,\n                                                   en  \\\n 0  And what I think the world needs now is more c...   \n 1  The group is named after Bangkok, the capital ...   \n 2  It is surrounded by rivers (Simpson and Coyhai...   \n \n                                                   vi  \n 0  Và tôi nghĩ điều thế giới đang cần bây giờ là ...  \n 1  Nhóm được đặt theo tên của Bangkok, thủ đô của...  \n 2  Nó được bao quanh bởi các con sông (Simpson và...  )"},"metadata":{}}]},{"cell_type":"markdown","source":"- So:\n\nThe training data has 500,000 rows.\n\nThe validation data has 11,316 rows.\n\nThe test data has 11225 rows.","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"- Check Missing values","metadata":{}},{"cell_type":"code","source":"print(\"Training Data: \")\nprint(df_train.isna().sum())\n\nprint(\"Validation Data: \")\nprint(df_valid.isna().sum())\n\nprint(\"Test Data: \")\nprint(df_test.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:23.521985Z","iopub.execute_input":"2024-06-16T09:36:23.522788Z","iopub.status.idle":"2024-06-16T09:36:23.582071Z","shell.execute_reply.started":"2024-06-16T09:36:23.522754Z","shell.execute_reply":"2024-06-16T09:36:23.581188Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training Data: \nen    0\nvi    0\ndtype: int64\nValidation Data: \nen    0\nvi    0\ndtype: int64\nTest Data: \nen    0\nvi    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- Sentences cleaning: some sentences will have a few mini errors. More than one ' ' or having special symbols for example.","metadata":{}},{"cell_type":"code","source":"def SentenceCleaning(df):\n\n    # Cleaning\n    df['en'] = df['en'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation))) # Make a new trans without punctuation\n    df['vi'] = df['vi'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n\n    df['en'] = df['en'].str.lower() # To easy and smaller vocab we should lower \n    df['vi'] = df['vi'].str.lower()\n\n    df['en'] = df['en'].str.strip() # clear spaces in the beginning and end of sentence\n    df['vi'] = df['vi'].str.strip()\n\n    df['en'] = df['en'].apply(lambda x: re.sub('\\s+',' ',x)) # replace '       ' to ' ' for example\n    df['vi'] = df['vi'].apply(lambda x: re.sub('\\s+',' ',x))\n\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:23.583129Z","iopub.execute_input":"2024-06-16T09:36:23.583454Z","iopub.status.idle":"2024-06-16T09:36:23.591270Z","shell.execute_reply.started":"2024-06-16T09:36:23.583427Z","shell.execute_reply":"2024-06-16T09:36:23.590284Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train = SentenceCleaning(df_train)\ndf_valid = SentenceCleaning(df_valid)\ndf_test = SentenceCleaning(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:23.592657Z","iopub.execute_input":"2024-06-16T09:36:23.593111Z","iopub.status.idle":"2024-06-16T09:36:31.352844Z","shell.execute_reply.started":"2024-06-16T09:36:23.593075Z","shell.execute_reply":"2024-06-16T09:36:31.352026Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:31.353981Z","iopub.execute_input":"2024-06-16T09:36:31.354312Z","iopub.status.idle":"2024-06-16T09:36:31.366000Z","shell.execute_reply.started":"2024-06-16T09:36:31.354285Z","shell.execute_reply":"2024-06-16T09:36:31.364986Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0                   sorry that questions not on here   \n1          he wants you to come with him immediately   \n2                i thought we could use some company   \n3  it was founded in 2008 by this anonymous progr...   \n4  with both of these methods no two prints are e...   \n5  from these contexts was born an installation i...   \n6  i have lived to see something which i never ex...   \n7  it is the model for all future relationships w...   \n8                        welcome him as your brother   \n9  so biologists can make all the mutant fruit fl...   \n\n                                                  vi  \n0        xin lỗi nhưng mà ở đây không có câu hỏi đấy  \n1          ông ấy muốn bố đi với ông ấy ngay lập tức  \n2  tôi nghĩ chúng ta có thể muốn vài người bạn đồ...  \n3  nó được sáng lập vào năm 2008 bởi một lập trìn...  \n4  với cả hai phương pháp không có hai bản in nào...  \n5  từ những tình huống này một bố trí không gian ...  \n6  ta đã sống để thấy điều ta không bao giờ mong đợi  \n7  đó là mô hình cho tất cả các mối quan hệ trong...  \n8                chào mừng nó như anh em của các con  \n9  vậy các nhà sinh vật học có thể biến đổi gene ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>vi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sorry that questions not on here</td>\n      <td>xin lỗi nhưng mà ở đây không có câu hỏi đấy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>he wants you to come with him immediately</td>\n      <td>ông ấy muốn bố đi với ông ấy ngay lập tức</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought we could use some company</td>\n      <td>tôi nghĩ chúng ta có thể muốn vài người bạn đồ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it was founded in 2008 by this anonymous progr...</td>\n      <td>nó được sáng lập vào năm 2008 bởi một lập trìn...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>with both of these methods no two prints are e...</td>\n      <td>với cả hai phương pháp không có hai bản in nào...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>from these contexts was born an installation i...</td>\n      <td>từ những tình huống này một bố trí không gian ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>i have lived to see something which i never ex...</td>\n      <td>ta đã sống để thấy điều ta không bao giờ mong đợi</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>it is the model for all future relationships w...</td>\n      <td>đó là mô hình cho tất cả các mối quan hệ trong...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>welcome him as your brother</td>\n      <td>chào mừng nó như anh em của các con</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>so biologists can make all the mutant fruit fl...</td>\n      <td>vậy các nhà sinh vật học có thể biến đổi gene ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"- Check for rows that contain words that are not within the range of the source and target languages\n\nBoth English and Vietnamese use the Latin alphabet, but Vietnamese adds diacritics to create special characters to represent different sounds. To filter out lines with words that do not belong to English and Vietnamese, we use appropriate regular expressions","metadata":{}},{"cell_type":"code","source":"def language_filter(df):\n    def is_valid_language_sentence(sentence):\n        pattern = re.compile(r'^[A-Za-zÀ-ỹà-ỹ\\s]*$')\n        return bool(pattern.match(sentence))\n    filtered_df = df[df['en'].apply(is_valid_language_sentence) & df['vi'].apply(is_valid_language_sentence)]\n    return filtered_df","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:31.409558Z","iopub.execute_input":"2024-06-16T09:36:31.410180Z","iopub.status.idle":"2024-06-16T09:36:31.415047Z","shell.execute_reply.started":"2024-06-16T09:36:31.410148Z","shell.execute_reply":"2024-06-16T09:36:31.414149Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train_filter = language_filter(df_train)\ndf_valid_filter = language_filter(df_valid)\ndf_test_filter = language_filter(df_test)\n\nprint(f'Train: before: {df_train.shape[0]} - after: {df_train_filter.shape[0]}')\nprint(f'valid: before: {df_valid.shape[0]} - after: {df_valid_filter.shape[0]}')\nprint(f'test: before: {df_test.shape[0]} - after: {df_test_filter.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:31.416251Z","iopub.execute_input":"2024-06-16T09:36:31.416585Z","iopub.status.idle":"2024-06-16T09:36:32.513444Z","shell.execute_reply.started":"2024-06-16T09:36:31.416562Z","shell.execute_reply":"2024-06-16T09:36:32.512491Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Train: before: 200000 - after: 156398\nvalid: before: 11316 - after: 8596\ntest: before: 11225 - after: 8560\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As we see, lots of rows have some words which are unrelated to its language! (20% - 30% data)\n\nIf we use the raw dataframe to create the vocabulary, the size will be very large leading to 'Issue 03: CUDA out of memory'.\n\nHow about using df_filter? Smaller size vocabulary will be created. But we will ignore correct words in invalid lines containing incorrect words and make the model ineffective.\n\n**My solution:** With the invalid rows, just remove the wrong words and use another words and valid words in valid rows to initialize a vocabulary. This will keep important word and minimize the unrelated words in vocabulary. (Reuslt: the size of the vocabulary has been halved)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:18:48.106916Z","iopub.execute_input":"2024-06-15T20:18:48.107611Z","iopub.status.idle":"2024-06-15T20:18:48.115417Z","shell.execute_reply.started":"2024-06-15T20:18:48.107577Z","shell.execute_reply":"2024-06-15T20:18:48.114210Z"}}},{"cell_type":"code","source":"def sentence_tomake_vocab(sentence):\n    sentence = re.sub(r'^[A-Za-zÀ-ỹà-ỹ\\s]*$', '', sentence)\n    return sentence\n\ndf_tomake_vocab = pd.concat([df_train, df_valid], ignore_index=True)\ndf_tomake_vocab['en'] = df_tomake_vocab['en'].apply(sentence_tomake_vocab)\ndf_tomake_vocab['vi'] = df_tomake_vocab['vi'].apply(sentence_tomake_vocab)\ndf_tomake_vocab = SentenceCleaning(df_tomake_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:32.514501Z","iopub.execute_input":"2024-06-16T09:36:32.514779Z","iopub.status.idle":"2024-06-16T09:36:37.134121Z","shell.execute_reply.started":"2024-06-16T09:36:32.514754Z","shell.execute_reply":"2024-06-16T09:36:37.133059Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"- Building **Tokenizer** and **Vocabulary**\n\nWith English - The most popular international language, **'torchtext.data.utils.get_tokenizer'** support the default language with 'en' - English. But Vietnamese has not already been supported.\n\nBut get_tokenizer allow us to transmission the function word_token returning a list to get_tokenizer. Then, the problems lead to what framework supports to Vietnamese. It must be Underthesea - the best support to Vietnamese in NLP\n\nYou can read **[torchtext - doc](https://pytorch.org/text/stable/data_utils.html)**!","metadata":{}},{"cell_type":"code","source":"SRC_LANGUAGE = 'en'\nTGT_LANGUAGE = 'vi'","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:37.135820Z","iopub.execute_input":"2024-06-16T09:36:37.136258Z","iopub.status.idle":"2024-06-16T09:36:37.142075Z","shell.execute_reply.started":"2024-06-16T09:36:37.136205Z","shell.execute_reply":"2024-06-16T09:36:37.139878Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"- **Tokenizer**","metadata":{}},{"cell_type":"code","source":"tokenizer = {}\n\n# Tokenizer for English\ntokenizer[SRC_LANGUAGE] = get_tokenizer('basic_english')\n\n# Tokenizer for Vietnamese\n# Need help with Underthesea\ndef vi_tokenize(sentence):\n    return word_tokenize(sentence) # word_tokenize from undersea supporting vietnamese\ntokenizer[TGT_LANGUAGE] = get_tokenizer(vi_tokenize)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:37.143194Z","iopub.execute_input":"2024-06-16T09:36:37.143508Z","iopub.status.idle":"2024-06-16T09:36:37.503908Z","shell.execute_reply.started":"2024-06-16T09:36:37.143484Z","shell.execute_reply":"2024-06-16T09:36:37.502801Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(tokenizer[SRC_LANGUAGE](\"hello can you help me\"))\nprint(tokenizer[TGT_LANGUAGE](\"xin chào bạn có thể giúp tôi không\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:37.505311Z","iopub.execute_input":"2024-06-16T09:36:37.505686Z","iopub.status.idle":"2024-06-16T09:36:37.978621Z","shell.execute_reply.started":"2024-06-16T09:36:37.505651Z","shell.execute_reply":"2024-06-16T09:36:37.977276Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['hello', 'can', 'you', 'help', 'me']\n['xin', 'chào bạn', 'có thể', 'giúp', 'tôi', 'không']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can clearly see that this Tokenizer will generate dictionaries with words and not characters as we tested before and failed.","metadata":{}},{"cell_type":"markdown","source":"- **Vocabulary**\n\nBuild a Vocab from an iterator.\n```python\ntorchtext.vocab.build_vocab_from_iterator(iterator: Iterable, min_freq: int = 1, specials: Optional[List[str]] = None, special_first: bool = True, max_tokens: Optional[int] = None) → Vocab\n```\n\n> - Parameters:\n\n**iterator** – Iterator used to build Vocab. Must **yield** list or iterator of tokens.\n\n**min_freq** – The minimum frequency needed to include a token in the vocabulary.\n\n**specials** – Special symbols to add. The order of supplied tokens will be preserved.\n\n**special_first** – Indicates whether to insert symbols at the beginning or at the end.\n\n**max_tokens** – If provided, creates the vocab from the max_tokens - len(specials) most frequent tokens.\n\n","metadata":{}},{"cell_type":"code","source":"def yield_token_helper(iterator : Iterable, language: str) -> List[str]:\n    for num_iter, sample_iter in iterator:\n        yield tokenizer[language](sample_iter[language])","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:37.980433Z","iopub.execute_input":"2024-06-16T09:36:37.980852Z","iopub.status.idle":"2024-06-16T09:36:37.986843Z","shell.execute_reply.started":"2024-06-16T09:36:37.980809Z","shell.execute_reply":"2024-06-16T09:36:37.985379Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Special Symbols\nUNKNOWN_TOKEN, PADDING_TOKEN, START_TOKEN, END_TOKEN = '<unk>', '<pad>', '<bos>', '<eos>'\nUNKNOWN_IDX, PADDING_IDX, START_IDX, END_IDX = 0,1,2,3","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:37.988738Z","iopub.execute_input":"2024-06-16T09:36:37.989193Z","iopub.status.idle":"2024-06-16T09:36:38.732196Z","shell.execute_reply.started":"2024-06-16T09:36:37.989140Z","shell.execute_reply":"2024-06-16T09:36:38.731090Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Building vocab\ndef vocab_building(df):\n    vocab = {}\n    for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n        iterator = df.iterrows()\n        vocab[language] = build_vocab_from_iterator(\n            iterator=yield_token_helper(iterator, language),\n            min_freq=1,\n            specials=[UNKNOWN_TOKEN, PADDING_TOKEN, START_TOKEN, END_TOKEN], # List special symbols\n            special_first=True\n        )\n\n    for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n        vocab[language].set_default_index(UNKNOWN_IDX)\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:38.735826Z","iopub.execute_input":"2024-06-16T09:36:38.736277Z","iopub.status.idle":"2024-06-16T09:36:38.816999Z","shell.execute_reply.started":"2024-06-16T09:36:38.736219Z","shell.execute_reply":"2024-06-16T09:36:38.815791Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"vocabulary = vocab_building(df_tomake_vocab)\nvocabulary","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:36:38.818484Z","iopub.execute_input":"2024-06-16T09:36:38.818818Z","iopub.status.idle":"2024-06-16T09:38:21.466241Z","shell.execute_reply.started":"2024-06-16T09:36:38.818793Z","shell.execute_reply":"2024-06-16T09:38:21.465356Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'en': Vocab(), 'vi': Vocab()}"},"metadata":{}}]},{"cell_type":"code","source":"vocabulary[SRC_LANGUAGE]['who']","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:21.467331Z","iopub.execute_input":"2024-06-16T09:38:21.467595Z","iopub.status.idle":"2024-06-16T09:38:21.473097Z","shell.execute_reply.started":"2024-06-16T09:38:21.467573Z","shell.execute_reply":"2024-06-16T09:38:21.472253Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"51"},"metadata":{}}]},{"cell_type":"code","source":"vocabulary[TGT_LANGUAGE]['nào']","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:21.474191Z","iopub.execute_input":"2024-06-16T09:38:21.474484Z","iopub.status.idle":"2024-06-16T09:38:21.485056Z","shell.execute_reply.started":"2024-06-16T09:38:21.474461Z","shell.execute_reply":"2024-06-16T09:38:21.484253Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"222"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building Complete Model \n\n- Use some of the classes, functions available in torch.nn. If you want a program from scratch, please check ModelBuilding.ipynb\n- Input/Output shape: (seq, batch, feature). We can change this by this parameter:\n\n```python \nbatch_first (bool)\n``` \n\n\n– If True, then the input and output tensors are provided as (batch, seq, feature). Default: False (seq, batch, feature).","metadata":{}},{"cell_type":"code","source":"class TokenEmbedding(nn.Module):\n    \n    def __init__(self, vocab_size:int, d_model:int):\n        super(TokenEmbedding, self).__init__()\n        self.embedding_layer = nn.Embedding(vocab_size, d_model)\n        self.d_model = d_model\n    \n    def forward(self, tokens: torch.Tensor):\n        return self.embedding_layer(tokens.long()) * math.sqrt(self.d_model)\n    \nclass PositionalEncoding(nn.Module):\n    \n    def __init__(self, max_length_seq:int, d_model:int, dropout_rate:float):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, d_model, 2)* math.log(10000) / d_model)\n        pos = torch.arange(0, max_length_seq).reshape(max_length_seq, 1)\n        PE = torch.zeros((max_length_seq, d_model))\n        PE[:, 0::2] = torch.sin(pos * den)\n        PE[:, 1::2] = torch.cos(pos * den)\n        PE = PE.unsqueeze(-2)\n        self.register_buffer(\"PE\", PE)\n        self.dropout_layer = nn.Dropout(dropout_rate)\n        \n    def forward(self, token_embedding: torch.Tensor):\n        return self.dropout_layer(token_embedding + self.PE[:token_embedding.size(0), :])\n    \nclass TransformerModel(nn.Module):\n    def __init__(self,\n                 src_vocab_size:int,\n                 tgt_vocab_size:int,\n                 d_model:int,\n                 nhead:int,\n                 num_encoder_layers:int,\n                 num_decoder_layers:int,\n                 dim_feedforward:int,\n                 dropout:float,\n                 max_length_seq=20000):\n        super(TransformerModel,self).__init__()\n        # Input Preprocessing\n        self.input_token_embedding = TokenEmbedding(vocab_size=src_vocab_size,d_model=d_model)\n        \n        # Output Preprocessing\n        self.output_token_embedding = TokenEmbedding(vocab_size=tgt_vocab_size,d_model=d_model)\n        \n        # Positional Encoding\n        self.positional_encoding = PositionalEncoding(max_length_seq=max_length_seq,d_model=d_model,dropout_rate=dropout)\n        \n        # Transformer Architecture with Encoder & Decoder (available nn.Transformer) \n        self.transformer = nn.Transformer(d_model=d_model,\n                                          nhead=nhead,\n                                          num_encoder_layers=num_encoder_layers,\n                                          num_decoder_layers=num_decoder_layers,\n                                          dim_feedforward=dim_feedforward,\n                                          dropout=dropout)\n        \n        # Linear Layer\n        self.generator = nn.Linear(d_model, tgt_vocab_size)\n    \n    def forward(self,\n                src: torch.Tensor,\n                tgt: torch.Tensor,\n                src_mask: torch.Tensor,\n                tgt_mask: torch.Tensor,\n                src_key_padding_mask: torch.Tensor,\n                tgt_key_padding_mask: torch.Tensor,\n                memory_key_padding_mask: torch.Tensor):\n        \n        # Pre-processing\n        src_embedding = self.positional_encoding(self.input_token_embedding(src))\n        tgt_embedding = self.positional_encoding(self.output_token_embedding(tgt))\n        \n        output = self.transformer(src_embedding, tgt_embedding, src_mask, tgt_mask, None, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\n        return self.generator(output)\n    \n    \n    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.input_token_embedding(src)), src_mask)\n\n    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: torch.Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.output_token_embedding(tgt)), memory,\n                          tgt_mask)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:21.486297Z","iopub.execute_input":"2024-06-16T09:38:21.486549Z","iopub.status.idle":"2024-06-16T09:38:21.504054Z","shell.execute_reply.started":"2024-06-16T09:38:21.486528Z","shell.execute_reply":"2024-06-16T09:38:21.503383Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class SupportTransformer:\n    \n    def __init__(self,\n                 device,\n                 src_language:str,\n                 tgt_language:str,\n                 start_idx:int,\n                 end_idx:int,\n                 pad_idx:int,\n                 unk_idx:int,\n                 tokenizer,\n                 vocabulary):\n        self.device = device\n        self.src_language = src_language\n        self.tgt_language = tgt_language\n        self.start_idx = start_idx\n        self.end_idx = end_idx\n        self.pad_idx = pad_idx\n        self.unk_idx = unk_idx\n        self.tokenizer = tokenizer\n        self.vocabulary = vocabulary\n    \n    def generate_square_subsequent_mask(self, size):\n        mask = (torch.triu(torch.ones((size, size), device=self.device)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_mask(self, src, tgt):\n        src_seq_len = src.shape[0]\n        tgt_seq_len = tgt.shape[0]\n\n        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n        src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n\n        src_padding_mask = (src == self.pad_idx).transpose(0, 1)\n        tgt_padding_mask = (tgt == self.pad_idx).transpose(0, 1)\n        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n    \n    def preprocessing_sentece(self, sentence:str, options=True): # True for src, False for tgt\n        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n        sentence = sentence.lower()\n        sentence = sentence.strip()\n        sentence = re.sub('\\s+', ' ', sentence)\n        \n        \n        lang = self.src_language if options else self.tgt_language\n        # Tokenizer\n        tokens = self.tokenizer[lang](sentence.rstrip(\"\\n\"))\n        # vocabulary: text -> number\n        tokens_idx = self.vocabulary[lang](tokens)\n        # Add start_token, end_token and append\n        return torch.cat((torch.tensor([self.start_idx]),\n                                      torch.tensor(tokens_idx),\n                                      torch.tensor([self.end_idx])))\n        \n    \n    def get_batch(self, df):\n        return list(zip(df[self.src_language], df[self.tgt_language]))\n    \n    def preprocessing_batch(self,batch):\n        src_out, tgt_out = [], []\n        \n        for src_data, tgt_data in batch:\n            src_out.append(self.preprocessing_sentece(src_data,options=True))\n            tgt_out.append(self.preprocessing_sentece(tgt_data,options=False))\n            \n        src_batch, tgt_batch = pad_sequence(src_out, padding_value=self.pad_idx), pad_sequence(tgt_out, padding_value=self.pad_idx)\n    \n        return src_batch, tgt_batch\n    \n    def evaluate(self, model, loss_func, df_valid, batch_size=30, accumulation_steps=5):\n        model.eval()\n        valid_loss = 0 \n        valid_batch = self.get_batch(df_valid)\n        valid_dataloader = DataLoader(valid_batch, batch_size=batch_size, collate_fn=self.preprocessing_batch)\n        for index, (src, tgt) in enumerate(valid_dataloader):\n            src = src.to(self.device)\n            tgt = tgt.to(self.device)\n            \n            tgt_input = tgt[:-1, :] # Without the last word\n            \n            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt_input)\n            \n            # predictions\n            predictions = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n            \n            tgt_out = tgt[1:, :]\n            # Loss\n            loss = loss_func(predictions.reshape(-1, predictions.shape[-1]), tgt_out.reshape(-1))\n            loss = loss / accumulation_steps\n            valid_loss += loss.item()\n            \n        return valid_loss / len(valid_dataloader)\n            \n        \n    \n    def train(self, model, optimizer, loss_func, df_train, batch_size = 30, accumulation_steps = 5):\n        model.train()\n        \n        train_loss = 0\n        train_batch = self.get_batch(df_train)\n        train_dataloader = DataLoader(train_batch, batch_size=batch_size, collate_fn=self.preprocessing_batch)\n        \n        # Reset grad\n        optimizer.zero_grad()\n        for index, (src, tgt) in enumerate(train_dataloader):\n            src = src.to(self.device)\n            tgt = tgt.to(self.device)\n            \n            tgt_input = tgt[:-1, :] # Without the last word\n            \n            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt_input)\n            \n            # predictions\n            predictions = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n            \n            tgt_out = tgt[1:, :]\n            # Loss\n            loss = loss_func(predictions.reshape(-1, predictions.shape[-1]), tgt_out.reshape(-1))\n            loss = loss / accumulation_steps\n            loss.backward()\n            \n            if (index+1) % accumulation_steps == 0:\n                optimizer.step()\n                optimizer.zero_grad() # Reset gradients tensor \n            train_loss += loss.item()\n            \n        return train_loss / len(train_dataloader)\n    \n    def generate(self, model, src_sentence):\n        start_symbol = self.start_idx\n        src = self.preprocessing_sentece(src_sentence, True).view(-1, 1)\n        max_len = src.shape[0]\n        src_mask = (torch.zeros(max_len, max_len)).type(torch.bool)\n        \n        src = src.to(self.device)\n        src_mask = src_mask.to(self.device)\n\n        memory = model.encode(src, src_mask)\n        ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(self.device)\n        for i in range(max_len-1):\n            memory = memory.to(self.device)\n            tgt_mask = (self.generate_square_subsequent_mask(ys.size(0))\n                        .type(torch.bool)).to(self.device)\n            out = model.decode(ys, memory, tgt_mask)\n            out = out.transpose(0, 1)\n            prob = model.generator(out[:, -1])\n            _, next_word = torch.max(prob, dim=1) # Greedy\n            next_word = next_word.item()\n\n            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n            if next_word == self.end_idx:\n                break\n\n        return \" \".join(\n            self.vocabulary[self.tgt_language].lookup_tokens(list(ys.cpu().numpy()))\n        ).replace(\n            self.vocabulary[self.tgt_language].lookup_token(self.start_idx), \"\"\n        ).replace(\n            self.vocabulary[self.tgt_language].lookup_token(self.end_idx), \"\"\n        ).strip()\n    \n    def completely_generate(self, model, src_sentence):\n        start_symbol = self.start_idx\n        src = self.preprocessing_sentece(src_sentence, True)\n        \n        src = src.view(-1, 1)\n        max_len = src.shape[0]\n        src_mask = (torch.zeros(max_len, max_len)).type(torch.bool)\n        \n        src = src.to(self.device)\n        src_mask = src_mask.to(self.device)\n\n        memory = model.encode(src, src_mask)\n        ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(self.device)\n        for i in range(max_len-1):\n            memory = memory.to(self.device)\n            tgt_mask = (self.generate_square_subsequent_mask(ys.size(0))\n                        .type(torch.bool)).to(self.device)\n            out = model.decode(ys, memory, tgt_mask)\n            out = out.transpose(0, 1)\n            prob = model.generator(out[:, -1])\n            _, next_word = torch.max(prob, dim=1) # Greedy\n            next_word = next_word.item()\n\n            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n            if next_word == self.end_idx:\n                break\n\n        # Find unkown words in tgt generate\n        tgt_unk_indexes = torch.nonzero(ys == self.unk_idx).squeeze().tolist()\n        \n        output_list = self.vocabulary[self.tgt_language].lookup_tokens(list(ys.cpu().numpy()))\n        src_tokens = self.tokenizer[self.src_language](src_sentence)\n        for index in tgt_unk_indexes:\n            if index[0]-1 < len(src_tokens):\n                output_list[index[0]] = src_tokens[index[0]-1]\n\n        \n        return \" \".join(\n            output_list\n        ).replace(\n            self.vocabulary[self.tgt_language].lookup_token(self.start_idx), \"\"\n        ).replace(\n            self.vocabulary[self.tgt_language].lookup_token(self.end_idx), \"\"\n        ).strip()\n    \n    def training(self, model, optimizer, loss_func, earlystopping, df_train, df_valid, epochs=5, batch_size = 30, accumulation_steps = 5, custom_test=None):\n        history = {'train_loss': [], 'valid_loss': []}\n        for epoch in range(1, epochs + 1):\n            print(f\"Epoch {epoch}: \" + (\"-\" * 80))\n            start = time.time()\n            train_loss = self.train(model, optimizer, loss_func, df_train, batch_size, accumulation_steps)\n            history['train_loss'].append(train_loss)\n            valid_loss = self.evaluate(model, loss_func, df_valid, batch_size)\n            history['valid_loss'].append(valid_loss)\n            print(f\"- Train loss: {train_loss:.3f} - Valid loss: {valid_loss:.3f} - Time training: {(time.time() - start):.3f}\")\n            \n            # custom_test\n            if custom_test != None:\n                print(f\"Input '{self.src_language}': {custom_test}\")\n                print(f\"Output '{self.tgt_language}' generate: {self.generate(model, custom_test)}\",end=\"\\n\\n\")\n            else:\n                print(\"\\n\\n\")\n                \n            # EarylyStopping\n            earlystopping(train_loss, valid_loss)\n            if earlystopping.early_stop:\n                print(\"Early Stopping active!\")\n                break\n        return history","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:59:14.369732Z","iopub.execute_input":"2024-06-16T10:59:14.370209Z","iopub.status.idle":"2024-06-16T10:59:14.415225Z","shell.execute_reply.started":"2024-06-16T10:59:14.370178Z","shell.execute_reply":"2024-06-16T10:59:14.414276Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Setup Model","metadata":{}},{"cell_type":"markdown","source":"- **Config**","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nsrc_vocab_size = len(vocabulary[SRC_LANGUAGE])\ntgt_vocab_size = len(vocabulary[TGT_LANGUAGE])\nd_model = 512\nnhead = 8 # d_model must be divisible by nhead\nnum_encoder_layers = 2\nnum_decoder_layers = 2\ndim_feedforward = 512\ndropout = 0.1\nEPOCHS = 5\nBATCH_SIZE = 30","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:21.552015Z","iopub.execute_input":"2024-06-16T09:38:21.552306Z","iopub.status.idle":"2024-06-16T09:38:21.585756Z","shell.execute_reply.started":"2024-06-16T09:38:21.552275Z","shell.execute_reply":"2024-06-16T09:38:21.585056Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"- **Model, Optimizer, EarlyStopping and Loss**","metadata":{"execution":{"iopub.status.busy":"2024-06-14T18:52:20.891679Z","iopub.execute_input":"2024-06-14T18:52:20.892297Z","iopub.status.idle":"2024-06-14T18:52:20.898207Z","shell.execute_reply.started":"2024-06-14T18:52:20.892265Z","shell.execute_reply":"2024-06-14T18:52:20.897134Z"}}},{"cell_type":"code","source":"model = TransformerModel(src_vocab_size=src_vocab_size,\n                         tgt_vocab_size=tgt_vocab_size,\n                         d_model=d_model,\n                         nhead=nhead,\n                         num_encoder_layers=num_encoder_layers,\n                         num_decoder_layers=num_decoder_layers,\n                         dim_feedforward=dim_feedforward,\n                         dropout=dropout)\nmodel = model.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:21.586833Z","iopub.execute_input":"2024-06-16T09:38:21.587598Z","iopub.status.idle":"2024-06-16T09:38:23.244519Z","shell.execute_reply.started":"2024-06-16T09:38:21.587573Z","shell.execute_reply":"2024-06-16T09:38:23.243622Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TransformerModel(\n  (input_token_embedding): TokenEmbedding(\n    (embedding_layer): Embedding(72982, 512)\n  )\n  (output_token_embedding): TokenEmbedding(\n    (embedding_layer): Embedding(71795, 512)\n  )\n  (positional_encoding): PositionalEncoding(\n    (dropout_layer): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=512, bias=True)\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): TransformerDecoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=512, bias=True)\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (generator): Linear(in_features=512, out_features=71795, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Initializing the weights of paramaters which have more than a dimension\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n        \n# Loss\nloss_func = nn.CrossEntropyLoss(ignore_index=PADDING_IDX)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\n# EarlyStopping\nclass EarlyStopping():\n    def __init__(self, tolerance=5, min_delta=0):\n\n        self.tolerance = tolerance\n        self.min_delta = min_delta\n        self.counter = 0\n        self.early_stop = False\n\n    def __call__(self, train_loss, validation_loss):\n        if (validation_loss - train_loss) > self.min_delta:\n            self.counter +=1\n            if self.counter >= self.tolerance:  \n                self.early_stop = True\n                \nearlystopping  = EarlyStopping(tolerance=5, min_delta=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:23.245573Z","iopub.execute_input":"2024-06-16T09:38:23.245844Z","iopub.status.idle":"2024-06-16T09:38:24.021492Z","shell.execute_reply.started":"2024-06-16T09:38:23.245822Z","shell.execute_reply":"2024-06-16T09:38:24.020553Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Training Model","metadata":{}},{"cell_type":"code","source":"sp = SupportTransformer(device=device,\n                        src_language=SRC_LANGUAGE,\n                        tgt_language=TGT_LANGUAGE,\n                        start_idx=START_IDX,\n                        end_idx=END_IDX,\n                        pad_idx=PADDING_IDX,\n                        unk_idx=UNKNOWN_IDX,\n                        tokenizer=tokenizer,\n                        vocabulary=vocabulary\n                       )\n \nhistory = sp.training(model=model,\n            optimizer=optimizer,\n            loss_func=loss_func,\n            earlystopping=earlystopping,\n            df_train=df_train,\n            df_valid=df_valid,\n            epochs=EPOCHS,\n            batch_size=BATCH_SIZE,\n            accumulation_steps=5,\n            custom_test=\"i like you\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:38:24.022615Z","iopub.execute_input":"2024-06-16T09:38:24.023045Z","iopub.status.idle":"2024-06-16T10:43:26.536749Z","shell.execute_reply.started":"2024-06-16T09:38:24.023020Z","shell.execute_reply":"2024-06-16T10:43:26.535832Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1: --------------------------------------------------------------------------------\n- Train loss: 1.229 - Valid loss: 1.016 - Time training: 781.452\nInput 'en': i like you\nOutput 'vi' generate: tôi như anh\n\nEpoch 2: --------------------------------------------------------------------------------\n- Train loss: 0.962 - Valid loss: 0.853 - Time training: 780.643\nInput 'en': i like you\nOutput 'vi' generate: tôi thích anh\n\nEpoch 3: --------------------------------------------------------------------------------\n- Train loss: 0.835 - Valid loss: 0.762 - Time training: 780.661\nInput 'en': i like you\nOutput 'vi' generate: tôi thích anh\n\nEpoch 4: --------------------------------------------------------------------------------\n- Train loss: 0.751 - Valid loss: 0.708 - Time training: 779.293\nInput 'en': i like you\nOutput 'vi' generate: tôi thích anh\n\nEpoch 5: --------------------------------------------------------------------------------\n- Train loss: 0.691 - Valid loss: 0.677 - Time training: 780.336\nInput 'en': i like you\nOutput 'vi' generate: tôi thích anh\n\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(history['train_loss'], label = \"train loss\")\nplt.plot(history['valid_loss'], label = \"valid loss\")\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss');","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:43:26.542357Z","iopub.execute_input":"2024-06-16T10:43:26.542628Z","iopub.status.idle":"2024-06-16T10:43:26.877693Z","shell.execute_reply.started":"2024-06-16T10:43:26.542605Z","shell.execute_reply":"2024-06-16T10:43:26.876757Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"def testing_generate(df, model, support:SupportTransformer, number=20,shuffle=False):\n    indexes = random.sample(range(len(df) + 1), number)\n    for index in indexes:\n        print('-' * 80,end='\\n\\n')\n        print(f\"Input '{support.src_language}': {df.iloc[index][support.src_language]}\")\n        print(f\"True Output '{support.tgt_language}': {df.iloc[index][support.tgt_language]}\")\n        print(f\"Generate Output '{support.tgt_language}': {support.generate(model,df.iloc[index][support.src_language])}\",end=\"\\n\\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:43:26.878839Z","iopub.execute_input":"2024-06-16T10:43:26.879124Z","iopub.status.idle":"2024-06-16T10:43:26.885452Z","shell.execute_reply.started":"2024-06-16T10:43:26.879099Z","shell.execute_reply":"2024-06-16T10:43:26.884538Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"testing_generate(df_test, model, sp, number=20, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:43:26.886417Z","iopub.execute_input":"2024-06-16T10:43:26.886703Z","iopub.status.idle":"2024-06-16T10:43:27.740927Z","shell.execute_reply.started":"2024-06-16T10:43:26.886679Z","shell.execute_reply":"2024-06-16T10:43:27.739975Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"--------------------------------------------------------------------------------\n\nInput 'en': you heard and were intrigued\nTrue Output 'vi': anh đã nghe và anh tò mò\nGenerate Output 'vi': anh nghe và chúng tôi đang <unk>\n\n--------------------------------------------------------------------------------\n\nInput 'en': im sorry i made him late\nTrue Output 'vi': tôi xin lỗi tôi khiến anh ấy bị muộn\nGenerate Output 'vi': tôi xin lỗi tôi đã làm ông ấy\n\n--------------------------------------------------------------------------------\n\nInput 'en': it took much courage to be here\nTrue Output 'vi': phải lấy rất nhiều can đảm để đến nơi đây\nGenerate Output 'vi': nó đã rất dũng cảm đến đây\n\n--------------------------------------------------------------------------------\n\nInput 'en': the script was researched and written by filmmaker s leigh savidge and radio veteran alan wenkus who worked closely with eazyes widow tomica woodswright\nTrue Output 'vi': kịch bản được nghiên cứu và viết bởi nhà làm phim s leigh savidge và alan wenkus người đã từng làm việc với góa phụ của eazye tomica woodswright\nGenerate Output 'vi': kịch bản được nghiên cứu và viết bởi nhà viết bởi nhà <unk> s <unk> và <unk> <unk> người đã làm việc chặt chẽ với <unk> <unk> <unk>\n\n--------------------------------------------------------------------------------\n\nInput 'en': soon after this event the lithuanian union of arts was founded and čiurlionis was one of its 19 founding members\nTrue Output 'vi': ngay sau sự kiện này liên hiệp nghệ thuật lithuanian được thành lập và čiurlionis là một trong 19 thành viên sáng lập của nó\nGenerate Output 'vi': ngay sau sự kiện này liên minh của nghệ thuật litva được thành lập và valdivia là một trong 19 thành viên sáng lập\n\n--------------------------------------------------------------------------------\n\nInput 'en': so in other words im making all of this up\nTrue Output 'vi': nói cách khác nghĩa là em đang bịa chuyện không anh không nói thế\nGenerate Output 'vi': vậy nên tôi làm tất cả những gì đó\n\n--------------------------------------------------------------------------------\n\nInput 'en': both warships continued to nouméa where the repair ship vestal repaired south dakotas collision and battle damage\nTrue Output 'vi': cả hai chiếc tàu tiếp tục đi đến nouméa nơi chiếc tàu sửa chữa vestal tiến hành phục hồi các hư hỏng của south dakota do tai nạn và trong chiến đấu\nGenerate Output 'vi': cả hai tàu chiến đều tiếp tục đến san diego nơi chiếc tàu sửa chữa tàu sân bay của tàu sân bay và trận\n\n--------------------------------------------------------------------------------\n\nInput 'en': the last president of the united states to wear any type of facial hair was william howard taft who was in office from 19091913\nTrue Output 'vi': tổng thống hoa kỳ cuối cùng mang ria mép là william howard taft người phục vụ từ năm 19091913\nGenerate Output 'vi': tổng thống cuối cùng của hoa kỳ để mặc bất kỳ loại tóc nào của tóc là william howard alfred miller người đang ở văn phòng từ <unk>\n\n--------------------------------------------------------------------------------\n\nInput 'en': inﬂuential powerful and respected by all\nTrue Output 'vi': có tầm ảnh hưởng quyền lực và được mọi người tôn trọng\nGenerate Output 'vi': <unk> mạnh mẽ và tôn trọng tất cả\n\n--------------------------------------------------------------------------------\n\nInput 'en': in 2004 she founded her own label angels dawn records under which she produced and launched her cd albita llegó that won her two grammys in the category of best contemporary tropical album\nTrue Output 'vi': năm 2004 bà thành lập nhãn hiệu riêng của mình angels dawn records theo đó bà đã sản xuất và ra mắt cd albita llegó đã giành được hai giải grammy của mình trong hạng mục album nhiệt đới đương đại hay nhất\nGenerate Output 'vi': năm 2004 bà thành lập hãng hàng không riêng của mình hãng hàng không fox records dưới đó bà sản xuất và ra mắt đĩa cd <unk> của cô đã giành được hai đĩa đơn của cô trong thể loại\n\n--------------------------------------------------------------------------------\n\nInput 'en': how did you know about the voice\nTrue Output 'vi': sao anh biết về giọng nói đó\nGenerate Output 'vi': làm sao anh biết về giọng nói\n\n--------------------------------------------------------------------------------\n\nInput 'en': created in 2016 the channel has received considerable media attention for its diy videos\nTrue Output 'vi': được tạo vào năm 2016 kênh đã nhận được sự chú ý của truyền thông nhờ các video diy của mình\nGenerate Output 'vi': được tạo ra trong năm 2016 kênh đã nhận được sự chú ý đáng kể cho các\n\n--------------------------------------------------------------------------------\n\nInput 'en': i still just want to draw out on this issue\nTrue Output 'vi': tôi vẫn muốn tiếp tục vấn đề này\nGenerate Output 'vi': tôi vẫn muốn vẽ ra vấn đề này\n\n--------------------------------------------------------------------------------\n\nInput 'en': keep those brands high on the hip so we can see them from a long way off\nTrue Output 'vi': đóng dấu cao lên trên hông để chúng ta có thể thấy từ xa\nGenerate Output 'vi': giữ các thương hiệu cao trên <unk> vì vậy chúng ta có thể thấy chúng từ một đường dài\n\n--------------------------------------------------------------------------------\n\nInput 'en': we are after all organic creatures and the culture of the school is absolutely essential\nTrue Output 'vi': chúng ta cuối cùng cũng là các sinh vật hữu cơ và nền văn hóa trường học là hoàn toàn cần thiết\nGenerate Output 'vi': chúng ta đang theo tất cả các sinh vật hữu cơ và văn hóa của trường là hoàn toàn cần thiết\n\n--------------------------------------------------------------------------------\n\nInput 'en': i thought you hated us\nTrue Output 'vi': tớ tưởng cậu ghét chúng tớ\nGenerate Output 'vi': tôi nghĩ anh <unk> chúng tôi\n\n--------------------------------------------------------------------------------\n\nInput 'en': the sarawak communist organisations guerrillas would fight alongside the tnku and indonesian forces during the indonesia–malaysia confrontation 1963–1966\nTrue Output 'vi': những quân du kích của tổ chức cộng sản sarawak chiến đấu bên quân đội quốc gia bắc kalimantan và lực lượng indonesia trong đối đầu indonesia–malaysia 1963–1966\nGenerate Output 'vi': các tổ chức cộng sản <unk> sẽ chiến đấu cùng với <unk> và indonesia trong cuộc đối đầu <unk> <unk>\n\n--------------------------------------------------------------------------------\n\nInput 'en': call me if you need a ride\nTrue Output 'vi': gọi mẹ nếu cần đi nhờ\nGenerate Output 'vi': gọi tôi nếu anh cần đi\n\n--------------------------------------------------------------------------------\n\nInput 'en': well if you want to have fun with us were right next door\nTrue Output 'vi': chúng tôi muốn vui đùa với anh chúng tôi chờ đây\nGenerate Output 'vi': nếu muốn có vui với chúng ta chúng ta chúng ta phải ngay cửa tiếp theo\n\n--------------------------------------------------------------------------------\n\nInput 'en': alfa team is green at this time one green two red\nTrue Output 'vi': đội alpha đã xanh một xanh hai đỏ\nGenerate Output 'vi': đội đặc nhiệm của đội là xanh trong thời gian này một màu xanh\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Save model & support","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = './model/translator_EnVi.pth'\nOPTIMIZER_PATH = './model/optimizer.pth'\nSUPPORT_PATH = './model/support_transformer.pkl'","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:43:27.742114Z","iopub.execute_input":"2024-06-16T10:43:27.742960Z","iopub.status.idle":"2024-06-16T10:43:27.746498Z","shell.execute_reply.started":"2024-06-16T10:43:27.742930Z","shell.execute_reply":"2024-06-16T10:43:27.745534Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./model/', exist_ok=True)\n\n# Save model state_dict\ntorch.save(model.state_dict(), MODEL_PATH)\n\n# Save optimizer state_dict\ntorch.save(optimizer.state_dict(), OPTIMIZER_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:43:27.747488Z","iopub.execute_input":"2024-06-16T10:43:27.747778Z","iopub.status.idle":"2024-06-16T10:43:30.534460Z","shell.execute_reply.started":"2024-06-16T10:43:27.747751Z","shell.execute_reply":"2024-06-16T10:43:30.533661Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Save helper\nwith open(SUPPORT_PATH, 'wb') as f:\n    pickle.dump(sp, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:59:51.044916Z","iopub.execute_input":"2024-06-16T10:59:51.045568Z","iopub.status.idle":"2024-06-16T10:59:51.096550Z","shell.execute_reply.started":"2024-06-16T10:59:51.045534Z","shell.execute_reply":"2024-06-16T10:59:51.095583Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Complete Generative Translator ","metadata":{}},{"cell_type":"code","source":"# Input Here\nsentence = \"Hey, do you know who i am?\"\nsp.completely_generate(model, sentence)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:59:52.347193Z","iopub.execute_input":"2024-06-16T10:59:52.347858Z","iopub.status.idle":"2024-06-16T10:59:52.379062Z","shell.execute_reply.started":"2024-06-16T10:59:52.347826Z","shell.execute_reply":"2024-06-16T10:59:52.378236Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'này anh biết tôi là ai'"},"metadata":{}}]},{"cell_type":"code","source":"sentence = \"Transformer is the best model for translating.\"\nsp.completely_generate(model, sentence)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:59:53.275138Z","iopub.execute_input":"2024-06-16T10:59:53.275521Z","iopub.status.idle":"2024-06-16T10:59:53.312431Z","shell.execute_reply.started":"2024-06-16T10:59:53.275492Z","shell.execute_reply":"2024-06-16T10:59:53.311617Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'transformer là mô hình tốt nhất cho thấy .'"},"metadata":{}}]},{"cell_type":"markdown","source":"## References","metadata":{}},{"cell_type":"markdown","source":"PyTorch. (n.d.). PyTorch. Retrieved June 15, 2024, from https://pytorch.org/docs/stable/index.html\n\nPyTorch. (n.d.). PyTorch text. Retrieved June 15, 2024, from https://pytorch.org/text/stable/\n\nNguyen, H. (n.d.). English to Vietnamese with Transformer. Kaggle. Retrieved June 15, 2024, from https://www.kaggle.com/code/huhuyngun/english-to-vietnamese-with-transformer","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}